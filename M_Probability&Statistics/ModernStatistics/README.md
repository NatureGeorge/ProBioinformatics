# Basic Concepts of Modern StatisticsğŸ±â€ğŸ

```txt
Created Date: Sunday, December 29th 2019, 4:00:12 pm
Author: ZeFeng Zhu
```

## Basic Statistical Test

### KeyğŸ¯

* ç»Ÿè®¡ä¸å˜å¼‚æ€§
  * æ ¹æœ¬ä¸Šï¼Œç»Ÿè®¡å­¦å¤„ç†å˜å¼‚æ€§åŠå˜å¼‚æ€§ä¸åŒçš„åŸå› 
  * å¯¹äºç”Ÿç‰©å­¦ä¸­è®¸å¤šæ¥æºçš„å˜å¼‚æ€§å®šé‡åŒ–æ˜¯å¾ˆé‡è¦çš„
    * åŒ…æ‹¬å®éªŒçš„ä¸ç²¾ç¡®
    * åŒä¸€ç‰©ç§ä¸åŒç”Ÿç‰©ä¸ªä½“é—´çš„å·®å¼‚
    * ç¯å¢ƒä¸­çš„å·®å¼‚
* æ£€éªŒçš„ç»Ÿè®¡å­¦æ„ä¹‰
  * ç»Ÿè®¡å­¦æ˜¾è‘—æ€§æ£€éªŒçš„ç›®çš„æ˜¯è¾¨åˆ«å…·æœ‰çœŸæ­£(ç”Ÿç‰©å­¦ etc.)æ„ä¹‰çš„éšæœºå˜åŒ–æ‰€å¯¼è‡´çš„å½±å“
* t-æ£€éªŒä¸æ›¿æ¢
  * t-æ£€éªŒçš„ç›®çš„æ˜¯æ£€éªŒæ­£æ€åˆ†å¸ƒæ•°æ®çš„å¹³å‡å€¼ä¹‹é—´å·®å¼‚çš„æ˜¾è‘—æ€§
  * Wilcoxon Test/Mann-Whitney Test for non-norm dist etc.
* æ–¹å·®åˆ†æ
  * å®éªŒä¸­æœ‰ä¸¤ç»„ä»¥ä¸Šæ•°æ®æ—¶ï¼Œé‡åŒ–ç»„å¹³å‡å€¼å·®å¼‚çš„æ˜¾è‘—æ€§
* å¡æ–¹æ£€éªŒ(Chi-square test)ä¸Fisherç²¾ç¡®æ£€éªŒ(Fisher's exact test)
  * ç»å¸¸ç”¨äºç”¨å…³è”è¡¨è¡¨ç¤ºçš„ç¦»æ•£â€œè®¡æ•°â€å‹æ•°æ®
  * ç›®çš„æ˜¯è¯„ä»·ï¼šå¦‚æœé›¶å‡è®¾æ˜¯çœŸçš„ï¼ŒæœŸæœ›çš„è®¡æ•°ä¹‹é—´çš„ç»Ÿè®¡å­¦æ„ä¹‰ï¼Œä»¥åŠæ¯ä¸ªç±»åˆ«ä¸­çš„å®é™…è§‚å¯Ÿè®¡æ•°
* åŸºäºå†å–æ ·çš„æ£€éªŒ
  * ä¸ºäº†è®¡ç®—på€¼ï¼Œå‡å®šé›¶å‡è®¾æ˜¯çœŸçš„ï¼Œæ›¿æ¢å¤§å¤šæ•°çš„ç»Ÿè®¡æ£€éªŒï¼Œå¹¶ä¸”é€šå¸¸åŒ…å«æ•°æ®çš„éšæœºåŒ–å–æ ·
* å¤šé‡æ£€éªŒ
  * å½“è¿›è¡Œä¸€æ¬¡ä»¥ä¸Šçš„ç»Ÿè®¡æ£€éªŒæ—¶ï¼Œæœ‰å¿…è¦å¯¹å¤šä¸ªé‡‡æ ·è¿›è¡Œæ ¡æ­£ï¼Œèƒ½ç»™å‡ºä¸€ä¸ªä¸æ­£ç¡®çš„å°på€¼
  * Bonferroniæ ¡æ­£
  * Benjamini-Hochbergæ ¡æ­£

### ç»Ÿè®¡ä¸å˜å¼‚æ€§

* æè¿°æ€§ç»Ÿè®¡
* ç®—æœ¯å¹³å‡å€¼
* ä¸­ä½æ•°
* æ ‡å‡†å·®
* å¼‚å¸¸å€¼
* å››åˆ†ä½æ•°

### æ£€éªŒçš„ç»Ÿè®¡å­¦æ„ä¹‰

__A frequently asked question:__ å¤§é‡çš„å˜å¼‚æ€§æ˜¯å¦å½’å› äºä¸€ä¸ªç‰¹å®šçš„å› ç´ ?

__For instance:__

* ç³–å°¿ç—…æ‚£è€…ä¸æ— è¯¥ç—…çš„æ‚£è€…ç›¸æ¯”æ˜¯å¦è¡€ç³–æ°´å¹³æœ‰æ‰€ä¸åŒ? $\Leftrightarrow$ ä¸¤ç»„æ‚£è€…ä¹‹é—´æµ‹é‡çš„è¡€ç³–å˜å¼‚æ€§æ˜¯å¦æ˜æ˜¾åŒºåˆ«äºå…¶ä»–å› ç´ çš„å˜å¼‚æ€§?

__How to solve:__

* åˆ©ç”¨ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒæ¥åŒºåˆ†éšæœºå‘ç”Ÿçš„å˜å¼‚æ€§(, æ¥çœ‹æ˜¯å¦æ•°æ®èƒ½å¤Ÿç»™å‡ºè¡€ç³–æ°´å¹³å·®å¼‚çš„ç¡®å®è¯æ®)
* ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒåŸºäºé›¶å‡è®¾ï¼Œå³â€œè§‚å¯Ÿåˆ°çš„æ•ˆåº”æ˜¯ç”±äºéšæœºå‘ç”Ÿâ€çš„å‡è®¾
* è¿›ä¸€æ­¥è®¡ç®—**åœ¨é›¶å‡è®¾ä¸ºçœŸçš„æ¡ä»¶ä¸‹**çš„æ¦‚ç‡ï¼Œç§°è¯¥æ¦‚ç‡ä¸ºp-value
  * å¦‚æœp-valueè¶³å¤Ÿå°ï¼Œé‚£ä¹ˆé›¶å‡è®¾å°±ä¸æˆç«‹ï¼Œæ•ˆåº”å°±ä¸æ˜¯éšæœºå‘ç”Ÿ
  * è‹¥é›¶å‡è®¾çš„p-valueå°äº0.05(95%æ˜¾è‘—æ€§æ°´å¹³)æˆ–æ›´å°ï¼Œå°äº0.01(99%æ˜¾è‘—æ€§æ°´å¹³)ï¼Œè¿™ç§æƒ…å†µå¸¸**è¢«**è®¤ä¸ºæ•ˆåº”æ˜¯æ˜¾è‘—çš„
  * è¡¨æ˜æ˜¾è‘—æ€§æ°´å¹³çš„p-valueæ˜¯ç”±è¯•éªŒè€…æ¥è®¾å®šçš„ï¼Œp-valueè¶Šå°ï¼Œå‡é˜³æ€§(éšæœºæ•ˆåº”è¢«å½’äºçœŸ)æ¦‚ç‡è¶Šå°ï¼Œä½†å‡é˜´æ€§(çœŸæ•ˆåº”è¢«å½’äºéšæœº)æ¦‚ç‡ä¼šå¢åŠ 

### t-æ£€éªŒä¸æ›¿æ¢

* t-teståŸºæœ¬å‡è®¾æ˜¯æ•°æ®ç¬¦åˆæ­£æ€åˆ†å¸ƒ
* t-test (Student's t-test)æ˜¯å¯¹æ ·æœ¬å‡å€¼è¿›è¡Œçš„æ˜¾è‘—æ€§æ£€éªŒ
* å•å› ç´ t-test: æ£€éªŒä¸€ä¸ªæ ·æœ¬çš„å‡å€¼ä¸ä¸€äº›ç¡®å®šå€¼æ˜¯å¦å­˜åœ¨æ˜¾è‘—æ€§å·®å¼‚
  * e.g æ£€éªŒæº¶æ¶²çš„è›‹ç™½è´¨æµ“åº¦ï¼Œå¯ä»¥ç”¨æ ‡å‡†çš„å·²çŸ¥æµ“åº¦ä½œä¸ºå‚è€ƒç‰©, å•å› ç´ t-testè¢«ç”¨äºæ£€éªŒç”¨ç›¸åŒæ£€æµ‹æ–¹æ³•é‡å¤çš„æµ‹é‡æ˜¯å¦ä¸å·²çŸ¥æµ“åº¦å­˜åœ¨å·®å¼‚
* åŒå› ç´ t-test: ä¸¤ä¸ªæ ·æœ¬çš„å‡å€¼ä¸å…¶ä»–æ¯ä¸€ä¸ªå€¼ä¹‹é—´æ˜¯å¦å­˜åœ¨æ˜¾è‘—æ€§å·®å¼‚
* Paired t-test: 
  * e.g 5ä¸ªå¿—æ„¿è€…é¤å‰é¤åæµ‹é‡çš„è¡€ç³–æ°´å¹³æ•°æ®å¯åˆ†ä¸º2ç»„ï¼Œæ•°æ®ä¸æ˜¯ç›¸äº’ç‹¬ç«‹çš„ï¼›åŒä¸€äººçš„æ•°æ®æ˜¯é…å¯¹çš„ï¼›paired t-testå°±æ˜¯æŠŠ5ä¸ªäººçš„10ä¸ªæ•°æ®è½¬åŒ–ä¸º5ä¸ªé¤å‰ä¸é¤åçš„è¡€ç³–æ°´å¹³ä¹‹å·®ï¼Œç„¶åç”¨å•å› ç´ t-testï¼Œçœ‹è¯¥å·®å€¼çš„å‡å€¼æ˜¯å¦ä¸0å­˜åœ¨æ˜¾è‘—æ€§å·®å¼‚
* å½“æ•°æ®ä¸æ˜¯æ­£æ€åˆ†å¸ƒæ—¶ï¼Œå¯ä½¿ç”¨Wilcoxonæ£€éªŒï¼Œè¿›è¡Œéå‚æ•°æ£€éªŒ

__Some details about the answer of the mentioned question:__

1. æ£€éªŒæ•°æ®æ˜¯å¦ç¬¦åˆæ­£æ€åˆ†å¸ƒ
2. å¦‚è‹¥ä¸æ˜¯åˆ™å°è¯•å‰”é™¤å¼‚å¸¸å€¼å†æ£€éªŒæ˜¯å¦ç¬¦åˆæ­£æ€åˆ†å¸ƒï¼Œè‹¥ç¬¦åˆåˆ™è¿›è¡Œä¸‹ä¸€æ­¥
3. åŒå› ç´ t-test
4. é‡‡ç”¨æ ‡å‡†å·®ä½œä¸ºå˜å¼‚åº¦ï¼Œä¸”å¾—åˆ°p-value
5. è¿›è¡Œåˆ¤æ–­

### æ–¹å·®åˆ†æ

* ä¸t-testä¸€æ ·ä¹Ÿæ£€éªŒæ•°æ®ç»„å‡å€¼ä¹‹é—´æ˜¯å¦å­˜åœ¨ç»Ÿè®¡æ˜¾è‘—æ€§å·®å¼‚ï¼Œä½†æ˜¯å…¶å¯ä»¥ç”¨äºè¶…è¿‡2ç»„çš„æ•°æ®æ£€éªŒ
* ä»¥æ–¹å·®ä¸ºæµ‹é‡å˜å¼‚åº¦çš„æŒ‡æ ‡
* Summary:
  * é¦–å…ˆæŠŠæ‰€æœ‰æ•°æ®æ··èµ·æ¥ä½œä¸ºä¸€ç»„æ•°æ®ï¼Œè®¡ç®—æ€»ä½“å‡å€¼ä¸æ€»ä½“æ–¹å·®
  * æ€»ä½“æ–¹å·®åˆ†è§£ä¸ºä¸¤éƒ¨åˆ†ï¼š
    * ç»„å†…æ–¹å·® (æ¯ç»„æ•°æ®å„è‡ªçš„æ–¹å·®)
    * ç»„é—´æ–¹å·® (ä¸åŒç»„å‡å€¼é—´çš„æ–¹å·®)
  * å¦‚æœç»„é—´æ–¹å·®æ¯”ç»„å†…æ–¹å·®æ›´é«˜ï¼Œé‚£ä¹ˆè¡¨ç¤ºæ•ˆåº”æ›´æ˜¾è‘—ï¼›åä¹‹éšæœºå› ç´ æ›´æ˜¾è‘—
  * é›¶å‡è®¾ï¼šæ‰€æœ‰ç»„çš„æ•°æ®å‡æ»¡è¶³ç›¸åŒå‡å€¼çš„æ­£æ€åˆ†å¸ƒ
  * ä¹Ÿæœ‰è¡¨ç¤ºé›¶å‡è®¾æ¦‚ç‡çš„p-value

__Sample problem:__ ç ”ç©¶10ç§è¯ç‰©å¯¹è¡€ç³–çš„å½±å“ï¼Œæ¯ä¸€ç»„æœ‰20äººæœç”¨åŒä¸€ç§è¯ç‰©(åŒ…æ‹¬å¯¹ç…§ç»„)ï¼Œ(æ›´å¤æ‚çš„åˆ†ç»„ï¼š20äººä¸€ç»„ä¸­ç”·å¥³å„10åçš„å­ç»„ç­‰)

__How to solve:__

1. æ–¹å·®åˆ†æï¼Œçœ‹ç»„å†…æ–¹å·®ä¸ç»„é—´æ–¹å·®çš„å¤§å°å…³ç³»ğŸ˜€
2. t-testä¸¤ä¸¤æ¯”è¾ƒ45æ¬¡ï¼Œå¤šé‡æ£€éªŒæ ¡æ­£p-valueğŸ˜¨

### Chi-square test & Fisher's exact test

__The reason to perform Chi-square test:__ ä¸€äº›å˜é‡ä¾‹å¦‚è¡€ç³–æ°´å¹³æ˜¯è¿ç»­å˜åŒ–çš„ï¼ŒåŸåˆ™ä¸Šå¯ä»¥å–ä»»æ„å€¼ï¼›ä½†**åˆ†ç±»å˜é‡**åªèƒ½å–ä¸€ç³»åˆ—ç¦»æ•£å€¼ã€‚åˆ†ç±»å˜é‡å¯ä»¥ç”¨äºå®šä¹‰t-testå’Œæ–¹å·®åˆ†æç»„ï¼Œä½†æœ‰æ—¶éœ€è¦å½“ä½œå› å˜é‡ï¼Œå¹¶å¯¹å®ƒä»¬çš„å€¼è¿›è¡Œç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒï¼Œå¸¸ç”¨çš„æ–¹æ³•å°±æ˜¯Chi-square($\chi^{2}$) testã€‚

__Sample Problem:__ 

* è¡¨ä¸­æ•°æ®æ˜¯ä¸€ç§æ¤ç‰©çš„3ä¸ªå˜å¼‚ä½“é­å—çš„æ—±ç¾åº”æ¿€
* å®éªŒè§‚å¯Ÿåˆ°çš„åŸºå› æ•°ç›®ç¬¦åˆæ­£æ€åˆ†å¸ƒ
* é—®é¢˜ï¼šå˜å¼‚ä½“æ˜¯å¦å¯¹åº”æ¿€æœ‰ä¸åŒçš„ååº”
* é›¶å‡è®¾ï¼šè¿™äº›å˜å¼‚ä½“å¯¹åº”æ¿€æ²¡æœ‰ä¸åŒçš„ååº”
* æ–œä½“æ•°å­—ç»™å‡ºæ¯ä¸ªç§ç±»æœŸæœ›çš„åŸºå› æ•°ï¼ŒæœŸæœ›å€¼å»ºç«‹åœ¨é›¶å‡è®¾ä¸ºçœŸçš„åŸºç¡€ä¸Š (e.g $43.8 = \frac{130}{178}*55$)

|   |å˜å¼‚ä½“A|å˜å¼‚ä½“B|å˜å¼‚ä½“C|æ€»åˆ|
|---|---|---|---|---|
|ç›¸å…³ä¸Šè°ƒåŸºå› åº”æ¿€æ•°|55 (*43.8*)|30 (*46.0*)|45 (*40.2*)|130|
|æ— å˜åŒ–è¡¨è¾¾æ•°|5 (*16.2*)|33 (*17.0*)|10 (*14.8*)|48|
|æ€»åˆ|60|63|55|178|

* ç»Ÿè®¡æ£€éªŒå…³æ³¨çš„å°±æ˜¯è§‚å¯Ÿè®¡æ•°(O)ä¸æœŸæœ›è®¡æ•°(E)ç›¸äº’ä¹‹é—´æ˜¯å¦å­˜åœ¨æ˜¾è‘—æ€§å·®å¼‚
* step:
  * å…ˆè®¡ç®—6æ ¼æ€»åˆçš„$\chi^{2}$ç»Ÿè®¡é‡$(O-E)^{2}/E$
    * è¿™ä¸ªæ€»åˆè¶Šå¤§è¯´æ˜é›¶å‡è®¾ä¸ºçœŸçš„æ¦‚ç‡è¶Šå¤§
  * p-valueç”±$\chi^{2}$ç»Ÿè®¡é‡çš„æ¦‚ç‡åˆ†å¸ƒå‡½æ•°å¾—åˆ°
* è‹¥2*2åˆ†ç±»è¡¨çš„æ•°æ®å°äºç­‰äº5ï¼Œåˆ™ä¸èƒ½ç”¨å¡æ–¹æ£€éªŒï¼Œå¯ä»¥ç”¨è´¹æ­‡å°”ç²¾ç¡®æ£€éªŒææ›¿ä»£

## Nonparametric tests

### KeyğŸ¯

* æ‹Ÿåˆä¼˜åº¦æ£€éªŒ
  * Q-Q plot `qqnorm(), qqline(), qqplot()`
  * æ­£æ€æ€§Wæ£€éªŒæ–¹æ³•
    * åˆ©ç”¨Shapiro-Wilkçš„Wç»Ÿè®¡é‡ä½œæ­£æ€æ€§æ£€éªŒ
    * `shapiro.test()`æä¾›Wç»Ÿè®¡é‡ä»¥åŠp-value
    * é›¶å‡è®¾: æ ·æœ¬æ¥è‡ªäºæ­£æ€åˆ†å¸ƒçš„æ€»ä½“
    * Large p-value does not prove that the distribution is normal - just not significantly differnet from normal
    * But it is too sensitive - one should use histogram/Q-Q plot when assessing t test/ANOVA assumptions
  * ç»éªŒåˆ†å¸ƒçš„Kolmogorov-Smirnovæ£€éªŒæ–¹æ³•
    * `ks.test()`
    * å•ä¸ªæ€»ä½“çš„æ£€éªŒ
      * é›¶å‡è®¾: Xå…·æœ‰åˆ†å¸ƒF
      * ç†è®ºä¸Šå¯ä»¥æ£€éªŒä»»ä½•åˆ†å¸ƒ
      * ç»éªŒåˆ†å¸ƒå‡½æ•°$F_n(x)$æ˜¯æ€»ä½“åˆ†å¸ƒå‡½æ•°$F(x)$çš„ä¼°è®¡
      * ç»éªŒåˆ†å¸ƒæ‹Ÿåˆæ£€éªŒçš„æ–¹æ³•æ˜¯æ£€éªŒ$F_n(x)$ä¸å‡è®¾çš„æ€»ä½“åˆ†å¸ƒå‡½æ•°$F_0(x)$ä¹‹é—´çš„å·®å¼‚
      * KSç»Ÿè®¡é‡: $D=\text{sup}_{-\infty \lt x \lt \infty} |F_n(x)-F_0(x)|$
    * ä¸¤ä¸ªæ€»ä½“çš„æ£€éªŒ
      * é›¶å‡è®¾: $F(x)=G(x)$
    * ä¸Pearson$\chi^{2}$æ£€éªŒç›¸æ¯”
      * ä¸éœ€è¦å°†æ ·æœ¬åˆ†ç»„ï¼Œå°‘ä¸€ä¸ªä»»æ„æ€§
      * ä½†æ˜¯åªèƒ½ç”¨åœ¨ç†è®ºåˆ†å¸ƒä¸º**ä¸€ç»´è¿ç»­åˆ†å¸ƒä¸”åˆ†å¸ƒå®Œå…¨å·²çŸ¥**çš„æƒ…å†µä¸‹ï¼Œé€‚ç”¨é¢æ›´å°
      * ä½†åœ¨å¯ç”¨åœºåˆä¸‹å…¶åŠŸæ•ˆä¸€èˆ¬ç•¥ä¼˜äºPearsonæ£€éªŒ
  * Neyman-Pearsonæ‹Ÿåˆä¼˜åº¦$\chi^{2}$æ£€éªŒ
    * `chisq.test(x, p=p)`
    * ç†è®ºåˆ†å¸ƒå·²çŸ¥
      * é›¶å‡è®¾: Xå…·æœ‰åˆ†å¸ƒF 
      * åˆ†ç»„åæ¯ç»„çš„é¢‘æ•°è¦å¤§äºç­‰äº5ï¼Œå¦åˆ™éœ€è¦åˆå¹¶ç»„æˆ–é‡‡ç”¨å…¶ä»–æ–¹æ³•(Fisher's exact test)
    * ç†è®ºåˆ†å¸ƒæœªçŸ¥ï¼Œä¾èµ–äºè‹¥å¹²ä¸ªæœªçŸ¥å‚æ•°
      * é€šè¿‡æ ·æœ¬åšå‡ºå„ä¸ªå‚æ•°çš„æœ€å¤§ä¼¼ç„¶ä¼°è®¡ï¼Œå†æ£€éªŒå‡è®¾: $H: \text{Xå…·æœ‰åˆ†å¸ƒ}F(x,\hat{\theta_{1}},\hat{\theta_{2}},...,\hat{\theta_{r}})$
      * ç„¶åå†æŒ‰ç†è®ºåˆ†å¸ƒå·²çŸ¥çš„æƒ…å†µè¿›è¡Œå¤„ç†
      * ä½†æ˜¯è‡ªç”±åº¦å˜ä¸º$m-1-r$ï¼Œå³è‡ªç”±åº¦å‡å°‘äº†r
* åˆ—è”è¡¨(Contingency table)æ•°æ®çš„ç‹¬ç«‹æ€§æ£€éªŒ
  * Pearson$\chi^{2}$æ£€éªŒ
    * è¾“å…¥åˆ—è”è¡¨æ•°æ®ï¼Œ`chisq.test()`å³å¯ä½œç‹¬ç«‹æ€§æ£€éªŒ
  * Fisher's exact test
    * åº”ç”¨: æ ·æœ¬è¾ƒå°(å•å…ƒçš„æœŸæœ›é¢‘æ•°å°äº(ç­‰äº)4)
    * æœ€åˆæ˜¯é’ˆå¯¹2*2è¿™ç§ç‰¹æ®Šåˆ—è”è¡¨æå‡º
    * å»ºç«‹åœ¨è¶…å‡ ä½•åˆ†å¸ƒçš„åŸºç¡€ä¸Š
    * `fisher.test()`
* ç¬¦å·æ£€éªŒ (Sign test)
  * æ£€éªŒä¸€ä¸ªæ ·æœ¬æ˜¯å¦æ¥è‡ªæŸä¸ªæ€»ä½“
    * ie. `binom.test(sum(X>99), length(X), al="l")`
  * ç”¨æˆå¯¹æ ·æœ¬æ¥æ£€éªŒä¸¤ä¸ªæ€»ä½“é—´æ˜¯å¦å­˜åœ¨å·®å¼‚
    * ie. `binom.test(sum(x<y), length(x))`
* ç§©æ£€éªŒ
  * ç§©ç»Ÿè®¡é‡ (Rank statistics)
    * åˆ†å¸ƒæ— å…³æ€§ (distribution-freeness)
  * ç§©ç›¸å…³æ£€éªŒ
    * Spearmanç§©ç›¸å…³æ£€éªŒ
    * Kendallç›¸å…³æ£€éªŒ
  * Wilcoxonç§©æ£€éªŒ
    * å¯¹æ¥è‡ªä¸€ä¸ªæ€»ä½“æ ·æœ¬çš„æ£€éªŒ
    * éæˆå¯¹æ ·æœ¬çš„ç§©æ¬¡å’Œæ£€éªŒ

### Sign testâš«âšª

#### æ£€éªŒä¸€ä¸ªæ ·æœ¬æ˜¯å¦æ¥è‡ªæŸä¸ªæ€»ä½“

å‡è®¾æŸä¸ªæ€»ä½“çš„ä¸­ä½æ•°ä¸º$M_0$,å¦‚æœæ ·æœ¬ä¸­ä½æ•°$M=M_0$ï¼Œæˆ‘ä»¬å°±æ¥å—æ ·æœ¬
æ¥è‡ªæŸä¸ªæ€»ä½“çš„å‡è®¾ã€‚

å…¶å…·ä½“çš„æ£€éªŒæ–¹æ³•æ˜¯è¿™æ ·çš„:

* é¦–å…ˆä»æ¯ä¸ªæ ·æœ¬è§‚å¯Ÿå€¼ä¸­å‡å»æ€»ä½“ä¸­ä½æ•°$M_0$ï¼Œå¾—å‡ºçš„æ­£ã€è´Ÿå·®é¢ç”¨æ­£(+)ã€è´Ÿ(-)å·åŠ ä»¥è¡¨ç¤º
* è‹¥æ€»ä½“ä¸­ä½æ•°ç­‰äºæ ·æœ¬ä¸­ä½æ•°ï¼Œå³$M=M_0$ï¼Œé‚£ä¹ˆï¼Œæ ·æœ¬è§‚å¯Ÿå€¼åœ¨ä¸­ä½æ•°ä¸Šã€ä¸‹çš„æ•°ç›®åº”å„å ä¸€åŠï¼Œå› ç°æ—¶å‡ºç°æ­£å·æˆ–è´Ÿå·çš„æ¦‚ç‡åº”å„å 1/2
* è®¾æ ·æœ¬å®¹é‡ä¸ºnå°±å¯ä»¥ç”¨äºŒé¡¹åˆ†å¸ƒ$B(n,1/2)$æ¥è®¡ç®—å‡ºç°è´Ÿå·ï¼ˆæˆ–æ­£å·ï¼‰ä¸ªæ•°çš„æ¦‚ç‡
* ä»è€Œæ ¹æ®ä¸€å®šçš„æ˜¾è‘—æ€§æ°´å¹³ä½œå‡ºæ˜¯å¦æ¥å—åŸå‡è®¾$H_0: M=M_0$çš„åˆ¤å®š

#### ç”¨æˆå¯¹æ ·æœ¬æ¥æ£€éªŒä¸¤ä¸ªæ€»ä½“é—´æ˜¯å¦å­˜åœ¨å·®å¼‚

ç¬¦å·æ£€éªŒæ³•ä¹Ÿå¯ç”¨äºä»¥æˆå¯¹éšæœºæ ·æœ¬è§‚å¯Ÿå€¼æ¥æ£€éªŒä¸¤ä¸ªæ€»ä½“ä¹‹é—´æ˜¯å¦å­˜åœ¨
æ˜¾è‘—å·®å¼‚ã€‚

å¦‚æœä¸¤ä¸ªæ€»ä½“æ— æ˜¾è€…å·®å¼‚ï¼Œåˆ™ä¸¤ä¸ªæˆå¯¹éšæœºæ ·æœ¬è§‚å¯Ÿå€¼æ­£ã€è´Ÿå·®é¢çš„ä¸ªæ•°åº”å¤§ä½“ç›¸ç­‰ï¼å‡å®š$x_i-y_i\gt 0$ç”¨æ­£å·è¡¨ç¤ºï¼Œ$x_i-y_i\lt 0$ç”¨è´Ÿå·è¡¨ç¤ºï¼Œåˆ™å¦‚æœä¸¤ä¸ªæ€»ä½“æ— æ˜¾æ˜¾è‘—å·®å¼‚ï¼Œé‚£ä¹ˆå‡ºç°æ­£å·å’Œè´Ÿå·çš„æ¦‚ç‡å„å 1/2ï¼Œå’Œä¸Šé¢æ£€éªŒæ ·æœ¬æ˜¯å¦æ¥è‡ªæŸä¸ªæ€»ä½“ä¸€æ ·ï¼Œå¯ç”¨äºŒé¡¹åˆ†å¸ƒ$B(n,1/2)$ï¼Œæ ¹æ®ä¸€å®šçš„æ˜¾è‘—æ€§æ°´å¹³å’Œæ­£å·ï¼ˆæˆ–è´Ÿå·ï¼‰çš„ä¸ªæ•°ï¼Œä½œå‡ºæ¥å—æˆ–æ‹’ç»ä¸¤ä¸ªæ€»ä½“æ— æ˜¾è‘—å·®å¼‚çš„åˆ¤æ–­

### ç§©æ£€éªŒğŸ¢

#### ç§©ç›¸å…³æ£€éªŒ

> Pearsonç›¸å…³æ£€éªŒé’ˆå¯¹äºæ­£æ€åˆ†å¸ƒæ€»ä½“çš„æ•°æ®ï¼Œç§©ç›¸å…³æ£€éªŒå¹¶ä¸è¦æ±‚æ‰€æ£€éªŒçš„æ•°æ®æ¥è‡ªæ­£æ€åˆ†å¸ƒçš„æ€»ä½“

* a measure of the strength and direction of **the monotonic relationship** between two variables
* Monotonicity is less restrictive than that of a linear relationship

##### Spearmanç§©ç›¸å…³æ£€éªŒ

* measures the strength and direction of monotonic association between two variables
* But a monotonic relationship is **not** strictly an assumption of Spearman's correlation. One can run a Spearman's correlation on a non-monotonic relationship to determinine if there is a monotonic component to the association
* For linear relationships, Pearson and Spearman correlations are nearly same
* For non-linear relationships, Pearson and Spearman correlations are different

##### Kendallç›¸å…³æ£€éªŒ

* A coefficient that represents the degree of concordance between two columns of ranked data
* The greater the number of "inversions" the smaller the coefficient will be

#### Wilcoxonç§©æ£€éªŒ (Wilcoxon Signed Rank Test)

* å¼¥è¡¥ç¬¦å·æ£€éªŒçš„ä¸è¶³ï¼Œåœ¨ä¸€å®šç¨‹åº¦ä¸Šè€ƒè™‘æ ·æœ¬è§‚å¯Ÿå€¼ä¸æ€»ä½“ä¸­ä½æ•°ä¹‹é—´çš„å·®é¢ï¼Œä¸ä»…æ˜¯ç¬¦å·(è¡¨å¾ä½äºä¸­å¿ƒä½ç½®çš„å“ªä¸€è¾¹)è¿˜æœ‰å€¼æ¥è¡¨å¾è·ç¦»ä¸­å¿ƒä½ç½®çš„è¿œè¿‘
* å‡è®¾
  * æ€»ä½“åˆ†å¸ƒæ˜¯è¿ç»­çš„
  * æ€»ä½“å¯¹å…¶ä¸­ä½æ•°æ˜¯å¯¹ç§°çš„
* `wilcox.test(x, y=NULL, alternative=c("two.sided", "less", "greater"), mu=0, paired=FALSE, exact=NULL, ...)`
  * mu: å¾…æ£€å‚æ•°ï¼Œå¦‚ä¸­ä½æ•°

##### å¯¹æ¥è‡ªä¸€ä¸ªæ€»ä½“æ ·æœ¬çš„æ£€éªŒ

* æ£€éªŒä¸€ä¸ªæ ·æœ¬æ˜¯å¦æ¥è‡ªæŸä¸ªæ€»ä½“ `wilcox.test(X, mu=140, alternative="less", comf.int=TRUE)`
* ç”¨äºå¯¹æˆå¯¹æ ·æœ¬çš„æ£€éªŒï¼Œä»è€Œè¯´æ˜ä¸¤ä¸ªæ€»ä½“æ˜¯å¦å­˜åœ¨æ˜¾è‘—å·®å¼‚ `wilcox.test(x, y, akternative="greater", paired=TRUE)`

##### éæˆå¯¹æ ·æœ¬çš„ç§©æ¬¡å’Œæ£€éªŒ

* ä¸¤éæˆå¯¹æ ·æœ¬è¦æ£€éªŒå…¶å¯¹åº”ä¸¤ä¸ªæ€»ä½“çš„ä¸­ä½æ•°æ˜¯å¦æƒ³ç­‰(è‹¥ä¸­ä½æ•°ç›¸ç­‰ï¼Œåˆ™è®¤ä¸ºä¸¤ä¸ªæ€»ä½“æ— å·®å¼‚)
* Wilcoxon-Mann-Whitneyç»Ÿè®¡é‡U
* ä¸¤ç»„æ ·æœ¬å¯ä»¥ä¸å¹³è¡¡
* `wilcox.test(x, y, alternative="less", exact=FALSE, correct=FALSE)`

## å¤šå…ƒæ•°æ®çš„æ•°æ®ç‰¹å¾ä¸ç›¸å…³åˆ†æ

### åæ–¹å·®

* åæ–¹å·®(corvarience)èƒ½åˆ†è¾¨å‡ºä¸¤å˜é‡çš„å…³ç³»:
  * æ­£ç›¸å…³ OR
  * è´Ÿç›¸å…³ OR
  * æ— ç›¸å…³
* But covariance is a **computational stepping stone** to something that is interesting, like correlation and PCA...
* Covariance values are **sensitive to the scale of data** and this makes them difficult to interpret
  * Covariance does not tell if the points are relatively close the line and if the slope is steep or not

### ç›¸å…³ç³»æ•° (Coeffcient of Correlation)

* Quantity the strength of the relationship(i.e bewteen X and Y) with correlation
  * Not 'CAUSE & EFFECT', just 'RELATION'
  * the more closer the data are to the line, the more X can tell about Y (given a x value, we might guess that the value for y falls in a smaller range)
* Maximum value for correlation is 1, minimum value is -1
* Does **not depend on the scale of data** (due to the denominator)
* But does not show the slope and need enough data to increase confidence
* Note: when talks about correlation, only use straight line
* For correlation, a p-value tells us the probability that randomly drawn dots will result in a similarly relationship, or stronger
* p-valueè¶Šå°ï¼Œå¯¹é¢„æµ‹ç»“æœçš„confidenceè¶Šå¤§
* æ ·æœ¬ç‚¹çš„å¢åŠ æœ¬è´¨ä¸Šæ˜¯å¢åŠ confidenceï¼Œç›¸å…³ç³»æ•°ä¸ä¸€å®šå¢åŠ 

> $R^{2}$å°†ä¼šæ¥è§£å†³ä¸¤ä¸ªç›¸å…³å…³ç³»å“ªä¸ªæ›´å¥½çš„é—®é¢˜(å•çœ‹ç›¸å…³ç³»æ•°æ— æ³•åˆ¤æ–­)

### äºŒå…ƒæ•°æ®çš„æ•°æ®ç‰¹å¾ä¸ç›¸å…³ç³»æ•°

* äºŒå…ƒæ€»ä½“$(X,Y)^{T}$

$$
A = \begin{bmatrix} 
x_{1} & x_{2} & ... & x_{n} \\
y_{1} & y_{2} & ... & y_{n} \\
\end{bmatrix}
$$

* è§‚æµ‹æ ·æœ¬çš„åæ–¹å·®é˜µ

$$
S = \begin{bmatrix} 
s_{xx} & s_{xy}\\
s_{xy} & s_{yy}\\
\end{bmatrix}
$$

* è§‚æµ‹æ ·æœ¬çš„ç›¸å…³ç³»æ•°

$$r=\cfrac{s_{xy}}{\sqrt{s_{xx}}\sqrt{s_{yy}}}$$


* Rå‡½æ•°
  * è®¡ç®—åæ–¹å·®é˜µ: `cov(x, y=NULL, use="all.obs", method=c("pearson", "kendall", "spearman"))`
  * è®¡ç®—ç›¸å…³ç³»æ•°çŸ©é˜µ: `cor(x, y=NULL, use="all.obs", method=c("pearson", "kendall", "spearman"))`

### äºŒå…ƒæ•°æ®çš„ç›¸å…³æ€§æ£€éªŒ

* æ€»ä½“çš„ç›¸å…³ç³»æ•°

$$\rho(X,Y)=\cfrac{\text{cov}(X,Y)}{\sqrt{\text{var(X)var(Y)}}}$$

* å½“æ ·æœ¬ä¸ªæ•°nå……åˆ†å¤§æ—¶ï¼Œ$r_{xy}$å¯ä»¥ä½œä¸º$\rho(X,Y)$çš„ä¼°è®¡
* Question: å½“æ ·æœ¬ä¸ªæ•°nè‡³å°‘å–åˆ°å¤šå°‘æ—¶ï¼Œæ ·æœ¬ç›¸å…³æ‰èƒ½ä¿è¯æ€»ä½“ç›¸å…³
* Anwser: ç¡®è®¤æ€»ä½“æ˜¯å¦ç›¸å…³æœ€æœ‰æ•ˆåŠæ³•æ˜¯ä½œæ€»ä½“$(X,Y)^{T}$çš„ç›¸å…³æ€§æ£€éªŒ
  * å¯ä»¥è¯æ˜ï¼Œè‹¥$(X,Y)^{T}$æ˜¯äºŒå…ƒæ­£æ€æ€»ä½“ï¼Œä¸”$\rho(X,Y)=0$ï¼Œåˆ™ç»Ÿè®¡é‡ $t=\cfrac{r_{xy}\sqrt{n-2}}{\sqrt{1-r_{xy}^{2}}}$æœä»è‡ªç”±åº¦ä¸ºn-2çš„tåˆ†å¸ƒ
  * åˆ©ç”¨ä¸Šè¿°æ€§è´¨å³å¯è¿›è¡ŒXå’ŒYçš„ç›¸å…³æ€§æ£€éªŒ
  * æ­¤æ—¶ç›¸å…³ç³»æ•°$r_{xy}$è¢«ç§°ä¸ºPearsonç›¸å…³ç³»æ•°ï¼Œå› æ­¤è¢«ç§°ä¸ºPearsonç›¸å…³æ€§æ£€éªŒ
* `cor.test(x, y, alternative=c("two.sided", "less", "greater"), method=c("pearson", "kendall", "spearman"), exact=NULL, conf.level=0.95, ...)`

## Linear Regression

### ä¸€å…ƒçº¿æ€§å›å½’

* å›å½’å‚æ•°çš„ä¼°è®¡
  * æœ€å°äºŒä¹˜æ³•
  * ...
* å›å½’æ–¹ç¨‹çš„æ˜¾è‘—æ€§æ£€éªŒ
  * t-test
  * F-test
  * ç›¸å…³ç³»æ•°æ£€éªŒ
* Related R function: `lm(), summary(), anova(), predict()`
* å‚æ•°$\beta_{0}, \beta_{1}$çš„åŒºé—´ä¼°è®¡
* é¢„æµ‹
* æ§åˆ¶

### å¤šå…ƒçº¿æ€§å›å½’

* å›å½’ç³»æ•°çš„ä¼°è®¡
* æ˜¾è‘—æ€§æ£€éªŒ
  * å›å½’ç³»æ•°çš„æ˜¾è‘—æ€§æ£€éªŒ
  * å›å½’æ–¹ç¨‹çš„æ˜¾è‘—æ€§æ£€éªŒ
* å‚æ•°$\beta$çš„åŒºé—´ä¼°è®¡
* é¢„æµ‹
* ä¿®æ­£æ‹Ÿåˆæ¨¡å‹

### é€æ­¥å›å½’

* `step()`

### å›å½’è¯Šæ–­

* WHAT
* æ®‹å·®åˆ†æ
  * æ®‹å·®å›¾
* å½±å“åˆ†æ
* å¤šé‡å…±çº¿æ€§

## æ–¹å·®åˆ†æ

### one-way ANOVA

* `aov(formula, data=NULL, ...)`
* å‡å€¼çš„å¤šé‡æ¯”è¾ƒ
  * å¤šé‡t-test
    * `pairwise.t.test(x, g, p.adjust.method)`
  * p-valueçš„ä¿®æ­£
    * `p.adjust(p, method)`
* æ–¹å·®çš„é½æ¬¡æ€§æ£€éªŒ
  * å¯åŠ æ€§
  * ç‹¬ç«‹æ­£æ€æ€§
    * `shapiro.test()`
  * æ–¹å·®é½æ€§
    * `bartlett.test()`
* Kruskal-Wallisç§©å’Œæ£€éªŒ
  * ä¸¤æ ·æœ¬çš„Wilcoxonæ–¹æ³•åœ¨å¤šäºä¸¤æ ·æœ¬æ—¶çš„æ¨å¹¿
  * `kruskal.test(x, g)`
* Friedmanç§©å’Œæ£€éªŒ
  * paired(é…ä¼ç»„)è®¾è®¡ä¸­ï¼Œå¤šä¸ªæ ·æœ¬çš„æ¯”è¾ƒï¼Œè‹¥å®ƒä»¬çš„æ€»ä½“ä¸èƒ½æ»¡è¶³æ­£æ€æ€§å’Œæ–¹å·®é½æ¬¡æ€§çš„è¦æ±‚ï¼Œå¯é‡‡ç”¨Friedmanç§©å’Œæ£€éªŒ
  * `fireman.test(y, groups, blocks, ...)`

### two-way ANOVA

* ä¸è€ƒè™‘äº¤äº’ä½œç”¨
  * `aov(Y ~ A+B, data=data)`
* è€ƒè™‘äº¤äº’ä½œç”¨
  * `aov(Y ~ A+B+A:B, data=data)`
* æ–¹å·®çš„é½æ¬¡æ€§æ£€éªŒ (same as one-way ANOVA)

## ReferenceğŸ‘©â€ğŸ’»

1. ğŸ“š BIOINFORMATICS (2nd Edition) _T.Charlie Hodgman, Andrew French, David R.Westhead..._
2. ğŸ“š ç»Ÿè®¡å»ºæ¨¡ä¸Rè½¯ä»¶ _è–›æ¯…, é™ˆç«‹è æ¸…åå¤§å­¦å‡ºç‰ˆç¤¾_
3. ğŸ“º [StatQuest: P Values, clearly explained](https://www.youtube.com/watch?v=5Z9OIYA8He8)
4. ğŸ“º [P-values and significance tests | AP Statistics | Khan Academy](https://www.youtube.com/watch?v=KS6KEWaoOOE) or [Hypothesis testing and p-values | Inferential statistics | Probability and Statistics | Khan Academy](https://www.youtube.com/watch?v=-FtlH4svqx4)
5. ğŸ“º [One-tailed and two-tailed tests | Inferential statistics | Probability and Statistics | Khan Academy](https://www.youtube.com/watch?v=mvye6X_0upA)
6. ğŸ“º [Z-statistics vs. T-statistics | Inferential statistics | Probability and Statistics | Khan Academy](https://www.youtube.com/watch?v=5ABpqVSx33I)
7. ğŸ“º [Pearson's chi square test (goodness of fit) | Probability and Statistics | Khan Academy](https://www.youtube.com/watch?v=2QeDRsxSF9M)
8. ğŸ“º [Contingency table chi-square test | Probability and Statistics | Khan Academy](https://www.youtube.com/watch?v=hpWdDmgsIRE)
9. ğŸ“º [StatQuest: Covariance and Correlation Part 1: Covariance](https://www.youtube.com/watch?v=qtaqvPAeEJY)
10. ğŸ“º [StatQuest: Covariance and Correlation Part 2: Pearson's Correlation](https://www.youtube.com/watch?v=xZ_z8KWkhXE)
11. ğŸ“º [Spearman Rank Correlation using R](https://www.youtube.com/watch?v=3R3z5uOFUic)
12. ğŸ“º [Kendall's tau - Explained Simply + Examples (part 1)](https://www.youtube.com/watch?v=oXVxaSoY94k)
13. ğŸ“º [9: Shapiro-Wilk test](https://www.youtube.com/watch?v=dRAqSsgkCUc)
